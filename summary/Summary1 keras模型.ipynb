{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11410227",
   "metadata": {},
   "source": [
    "\n",
    "## 模型使用\n",
    "Keras通过两个API提供两种计算模型：\n",
    "- 函数式模型：通过Model类API；\n",
    "- 顺序式模型：通过Sequential类API；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb47c11",
   "metadata": {},
   "source": [
    "## 顺序式模型\n",
    "\n",
    "<code> model=tf.keras.Sequential()\n",
    "\n",
    "Layer提供input与output属性:  \n",
    "    \n",
    "Sequential类通过Layer的input与output属性来维护层之间的关系，构建网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a265437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a66325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5a86d2",
   "metadata": {},
   "source": [
    "## layers网络层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c18776",
   "metadata": {},
   "source": [
    "### Dense全连接层\n",
    "\n",
    "全连接层（对上一层的神经元进行全部连接，实现特征的非线性组合）  \n",
    "第一层需要指定 input_shape=( ,)\n",
    "\n",
    "<code>keras.layers.Dense(units, \n",
    "\t\t\t\t  activation=None, \n",
    "\t\t\t\t  use_bias=True, \n",
    "\t\t\t\t  kernel_initializer='glorot_uniform', \n",
    "\t\t\t\t  bias_initializer='zeros', \n",
    "\t\t\t\t  kernel_regularizer=None, \n",
    "\t\t\t\t  bias_regularizer=None, \n",
    "\t\t\t      activity_regularizer=None, \n",
    "\t\t\t\t  kernel_constraint=None,  \n",
    "units: 正整数，输出空间维度。  注意输出结果维度，二分类问题 units=1\n",
    "activation: 激活函数 (详见 activations)。 若不指定，则不使用激活函数 (即，「线性」激活: a(x) = x)。\n",
    "use_bias: 布尔值，该层是否使用偏置向量。\n",
    "kernel_initializer: kernel 权值矩阵的初始化器 (详见 initializers)。\n",
    "bias_initializer: 偏置向量的初始化器 (see initializers).\n",
    "kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数 (详见 regularizer)。\n",
    "bias_regularizer: 运用到偏置向的的正则化函数 (详见 regularizer)。\n",
    "activity_regularizer: 运用到层的输出的正则化函数 (它的 \"activation\")。 (详见 regularizer)。\n",
    "kernel_constraint: 运用到 kernel 权值矩阵的约束函数 (详见 constraints)。\n",
    "bias_constraint: 运用到偏置向量的约束函数 (详见 constraints)。\n",
    "    \n",
    "    输入尺寸  \n",
    "    nD 张量，尺寸: (batch_size, ..., input_dim)。 最常见的情况是一个尺寸为 (batch_size, input_dim) 的 2D 输入。\n",
    "\n",
    "    输出尺寸  \n",
    "    nD 张量，尺寸: (batch_size, ..., units)。 例如，对于尺寸为 (batch_size, input_dim) 的 2D 输入， 输出的尺寸为 (batch_size, units)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c069545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(64,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8a0d1",
   "metadata": {},
   "source": [
    "### Activation\n",
    "将激活函数应用于输出。\n",
    "\n",
    "<code>keras.layers.Activation(activation)\n",
    "\n",
    "    输入尺寸  \n",
    "    任意尺寸。 当使用此层作为模型中的第一层时， 使用参数 input_shape （整数元组，不包括样本数的轴）。\n",
    "\n",
    "    输出尺寸  \n",
    "    与输入相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04a81c",
   "metadata": {},
   "source": [
    "### Flatten\n",
    "将输入展平。不影响批量大小。\n",
    "<code>\n",
    "    keras.layers.Flatten(data_format=None)\n",
    "例：\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3),input_shape=(3, 32, 32), padding='same',))   # 现在：model.output_shape == (None, 64, 32, 32)\n",
    "    model.add(Flatten())                                    # 现在：model.output_shape == (None, 65536)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d1f4e",
   "metadata": {},
   "source": [
    "### Embedding 层\n",
    "文本数据\n",
    "\n",
    "将正整数转换为固定尺寸的密集向量  \n",
    "可以从文本数据中学习字嵌入，并在项目之间重复使用，\n",
    "- Embedding层只能作为模型的第一层  \n",
    "- **需要指明input_length=**\n",
    "\n",
    "\n",
    "<code>\n",
    "    keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "模型将输入一个大小为 (batch, input_length) 的整数矩阵。\n",
    "输入中最大的整数（即词索引）不应该大于 999 （词汇表大小）\n",
    "input_dim: int > 0。词汇表大小， 即，最大整数 index + 1。\n",
    "output_dim: int >= 0。词向量的维度。\n",
    "embeddings_initializer: embeddings 矩阵的初始化方法 (详见 initializers)。\n",
    "embeddings_regularizer: embeddings matrix 的正则化方法 (详见 regularizer)。\n",
    "embeddings_constraint: embeddings matrix 的约束函数 (详见 constraints)。\n",
    "mask_zero: 是否把 0 看作为一个应该被遮蔽的特殊的 \"padding\" 值。 这对于可变长的 循环神经网络层 十分有用。 如果设定为 True，那么接下来的所有层都必须支持 masking，否则就会抛出异常。 如果 mask_zero 为 True，作为结果，索引 0 就不能被用于词汇表中 （input_dim 应该与 vocabulary + 1 大小相同）。\n",
    "input_length: 输入序列的长度，当它是固定的时。 如果你需要连接 Flatten 和 Dense 层，则这个参数是必须的 （没有它，dense 层的输出尺寸就无法计算）。\n",
    "    \n",
    "    输入 2D,输出3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de322b",
   "metadata": {},
   "source": [
    "### 池化层pooling\n",
    "\n",
    "- GlobalAveragePooling1D  \n",
    "对于时序数据的全局平均池化。\n",
    "\n",
    "<code> keras.layers.GlobalAveragePooling1D()\n",
    "\n",
    "     输入尺寸\n",
    "    如果 data_format='channels_last'， 输入为 3D 张量，尺寸为： (batch_size, steps, features)\n",
    "    如果data_format='channels_first'， 输入为 3D 张量，尺寸为： (batch_size, features, steps)\n",
    "     输出尺寸\n",
    "    尺寸是 (batch_size, features) 的 2D 张量。\n",
    "\n",
    "- GlobalMaxPooling2D  \n",
    "    对于空域数据的全局最大池化。\n",
    "    \n",
    "<code> keras.layers.GlobalAveragePooling2D()\n",
    "     \n",
    "    输入尺寸  \n",
    "    如果 data_format='channels_last': 尺寸是 (batch_size, rows, cols, channels) 的 4D 张量  \n",
    "    如果 data_format='channels_first': 尺寸是 (batch_size, channels, rows, cols) 的 4D 张量  \n",
    "    输出尺寸  \n",
    "    尺寸是 (batch_size, channels) 的 2D 张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3898eca0",
   "metadata": {},
   "source": [
    "### 卷积层Convlutional\n",
    "\n",
    "- Conv1D 1D卷积层\n",
    "    (例如时序卷积)。\n",
    "\n",
    "当使用该层作为模型第一层时，需要提供 input_shape 参数（整数元组或 None），例如， (10, 128) 表示 10 个 128 维的向量组成的向量序列， (None, 128) 表示 128 维的向量组成的变长序列\n",
    "\n",
    "<code>keras.layers.Conv1D(filters, kernel_size, strides=1, padding='valid', data_format='channels_last', dilation_rate=1, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "\n",
    "    输入尺寸  \n",
    "    3D 张量 ，尺寸为 (batch_size, steps, input_dim)。\n",
    "\n",
    "    输出尺寸  \n",
    "    3D 张量，尺寸为 (batch_size, new_steps, filters)。 由于填充或窗口按步长滑动，steps 值可能已更改。\n",
    "\n",
    "- Conv2D\n",
    "    2D 卷积层 (例如对图像的空间卷积)。\n",
    "\n",
    "    当使用该层作为模型第一层时，需要提供 input_shape 参数 （整数元组，不包含样本表示的轴），例如， input_shape=(128, 128, 3) 表示 128x128 RGB 图像， 在 data_format=\"channels_last\" 时\n",
    "    \n",
    "<code>keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "filters: 整数，输出空间的维度 （即卷积中滤波器的输出数量）。\n",
    "kernel_size: 一个整数，或者 2 个整数表示的元组或列表， 指明 2D 卷积窗口的宽度和高度。 可以是一个整数，为所有空间维度指定相同的值。\n",
    "strides: 一个整数，或者 2 个整数表示的元组或列表， 指明卷积沿宽度和高度方向的步长。 可以是一个整数，为所有空间维度指定相同的值。 指定任何 stride 值 != 1 与指定 dilation_rate 值 != 1 两者不兼容。\n",
    "padding: \"valid\" 或 \"same\" (大小写敏感)。\n",
    "data_format: 字符串， channels_last (默认) 或 channels_first 之一，表示输入中维度的顺序。 channels_last 对应输入尺寸为 (batch, height, width, channels)， channels_first 对应输入尺寸为 (batch, channels, height, width)。 它默认为从 Keras 配置文件 ~/.keras/keras.json 中 找到的 image_data_format 值。 如果你从未设置它，将使用 channels_last。\n",
    "dilation_rate: 一个整数或 2 个整数的元组或列表， 指定膨胀卷积的膨胀率。 可以是一个整数，为所有空间维度指定相同的值。 当前，指定任何 dilation_rate 值 != 1 与 指定 stride 值 != 1 两者不兼容。\n",
    "activation: 要使用的激活函数 (详见 activations)。 如果你不指定，则不使用激活函数 (即线性激活： a(x) = x)。\n",
    "use_bias: 布尔值，该层是否使用偏置向量。\n",
    "kernel_initializer: kernel 权值矩阵的初始化器 (详见 initializers)。\n",
    "bias_initializer: 偏置向量的初始化器 (详见 initializers)。\n",
    "kernel_regularizer: 运用到 kernel 权值矩阵的正则化函数 (详见 regularizer)。\n",
    "bias_regularizer: 运用到偏置向量的正则化函数 (详见 regularizer)。\n",
    "activity_regularizer: 运用到层输出（它的激活值）的正则化函数 (详见 regularizer)。\n",
    "kernel_constraint: 运用到 kernel 权值矩阵的约束函数 (详见 constraints)。\n",
    "bias_constraint: 运用到偏置向量的约束函数 (详见 constraints)。\n",
    "\n",
    "    输入尺寸  \n",
    "    如果 data_format='channels_first'， 输入 4D 张量，尺寸为 (samples, channels, rows, cols)。  \n",
    "    如果 data_format='channels_last'， 输入 4D 张量，尺寸为 (samples, rows, cols, channels)。 \n",
    "    \n",
    "    输出尺寸  \n",
    "    如果 data_format='channels_first'， 输出 4D 张量，尺寸为 (samples, filters, new_rows, new_cols)。  \n",
    "    如果 data_format='channels_last'， 输出 4D 张量，尺寸为 (samples, new_rows, new_cols, filters)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3598c1de",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\anaconda\\envs\\tensor_flow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2519\u001b[0m     \"\"\"\n\u001b[0;32m   2520\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2521\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2522\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea7aa5",
   "metadata": {},
   "source": [
    "## 实例化model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbed026",
   "metadata": {},
   "source": [
    "### compile\n",
    "    用于配置训练模型\n",
    "\n",
    "<code>model.compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "    \n",
    "- optimizer: 字符串（优化器名）或者优化器实例。 详见 optimizers。\n",
    "- loss: 字符串（目标函数名）或目标函数。 详见 losses。 如果模型具有多个输出，则可以通过传递损失函数的字典或列表，在每个输出上使用不同的损失。 模型将最小化的损失值将是所有单个损失的总和。\n",
    "- metrics: 在训练和测试期间的模型评估标准。 通常你会使用 metrics = ['accuracy']。 要为多输出模型的不同输出指定不同的评估标准， 还可以传递一个字典，如 metrics = {'output_a'：'accuracy'}。\n",
    "- loss_weights: 可选的指定标量系数（Python 浮点数）的列表或字典， 用以衡量损失函数对不同的模型输出的贡献。 模型将最小化的误差值是由 - -  loss_weights 系数加权的加权总和误差。 如果是列表，那么它应该是与模型输出相对应的 1:1 映射。 如果是张量，那么应该把输出的名称（字符串）映到标量系数。\n",
    "- sample_weight_mode: 如果你需要执行按时间步采样权重（2D 权重），请将其设置为 temporal。 默认为 None，为采样权重（1D）。 如果模型有多个输出，则可以通过传递 mode 的字典或列表，以在每个输出上使用不同的 sample_weight_mode。\n",
    "- weighted_metrics: 在训练和测试期间，由 sample_weight 或 class_weight 评估和加权的度量标准列表。\n",
    "- target_tensors: 默认情况下，Keras 将为模型的目标创建一个占位符，在训练过程中将使用目标数据。 相反，如果你想使用自己的目标张量（反过来说，Keras 在训练期间不会载入这些目标张量的外部 Numpy 数据）， 您可以通过 target_tensors 参数指定它们。 它可以是单个张量（单输出模型），张量列表，或一个映射输出名称到目标张量的字典。\n",
    "**kwargs: 当使用 Theano/CNTK 后端时，这些参数被传入 K.function。 当使用 TensorFlow 后端时，这些参数被传递到 tf.Session.run。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f917957b",
   "metadata": {},
   "source": [
    "### fit\n",
    "以给定数量的轮次（数据集上的迭代）训练模型。\n",
    "\n",
    "<code> model.fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None)<code/>\n",
    "\n",
    "    参数\n",
    "\n",
    "- x: 训练数据的 Numpy 数组（如果模型只有一个输入）， 或者是 Numpy 数组的列表（如果模型有多个输入）。 如果模型中的输入层被命名，你也可以传递一个字典，将输入层名称映射到 Numpy 数组。 如果从本地框架张量馈送（例如 TensorFlow 数据张量）数据，x 可以是 None（默认）。\n",
    "- y: 目标（标签）数据的 Numpy 数组（如果模型只有一个输出）， 或者是 Numpy 数组的列表（如果模型有多个输出）。 如果模型中的输出层被命名，你也可以传递一个字典，将输出层名称映射到 Numpy 数组。 如果从本地框架张量馈送（例如 TensorFlow 数据张量）数据，y 可以是 None（默认）。\n",
    "- batch_size: 整数或 None。每次梯度更新的样本数。如果未指定，默认为 32。\n",
    "- epochs: 整数。训练模型迭代轮次。一个轮次是在整个 x 和 y 上的一轮迭代。 请注意，与 initial_epoch 一起，epochs 被理解为 「最终轮次」。模型并不是训练了 epochs 轮，而是到第 epochs 轮停止训练。\n",
    "- verbose: 0, 1 或 2。日志显示模式。 0 = 安静模式, 1 = 进度条, 2 = 每轮一行。\n",
    "- callbacks: 一系列的 keras.callbacks.Callback 实例。一系列可以在训练时使用的回调函数。 详见 callbacks。\n",
    "- validation_split: 0 和 1 之间的浮点数。用作验证集的训练数据的比例。 模型将分出一部分不会被训练的验证数据，并将在每一轮结束时评估这些验证数据的误差和任何其他模型指标。 验证数据是混洗之前 x 和y 数据的最后一部分样本中。\n",
    "- validation_data: 元组 (x_val，y_val) 或元组 (x_val，y_val，val_sample_weights)， 用来评估损失，以及在每轮结束时的任何模型度量指标。 模型将不会在这个数据上进行训练。这个参数会覆盖 validation_split。\n",
    "- shuffle: 布尔值（是否在每轮迭代之前混洗数据）或者 字符串 (batch)。 batch 是处理 HDF5 数据限制的特殊选项，它对一个 batch 内部的数据进行混洗。 当 steps_per_epoch 非 None 时，这个参数无效。\n",
    "- class_weight: 可选的字典，用来映射类索引（整数）到权重（浮点）值，用于加权损失函数（仅在训练期间）。 这可能有助于告诉模型 「更多关注」来自代表性不足的类的样本。\n",
    "- sample_weight: 训练样本的可选 Numpy 权重数组，用于对损失函数进行加权（仅在训练期间）。 您可以传递与输入样本长度相同的平坦（1D）Numpy 数组（权重和样本之间的 1:1 映射）， 或者在时序数据的情况下，可以传递尺寸为 (samples, sequence_length) 的 2D 数组，以对每个样本的每个时间步施加不同的权重。 在这种情况下，你应该确保在 compile() 中指定 sample_weight_mode=\"temporal\"。\n",
    "- initial_epoch: 整数。开始训练的轮次（有助于恢复之前的训练）。\n",
    "- steps_per_epoch: 整数或 None。 在声明一个轮次完成并开始下一个轮次之前的总步数（样品批次）。 使用 TensorFlow 数据张量等输入张量进行训练时，默认值 None 等于数据集中样本的数量除以 batch 的大小，如果无法确定，则为 1。\n",
    "- validation_steps: 只有在指定了 steps_per_epoch 时才有用。停止前要验证的总步数（批次样本）。\n",
    "\n",
    "于一般用到x=None, y=None, batch_size=None,validation_data=（test,test）, \n",
    "  \n",
    "**返回**\n",
    "一个 History 对象。其 History.history 属性是连续 epoch 训练损失和评估值，以及验证集损失和评估值的记录（如果适用）。\n",
    "    \n",
    "<code> history.history.keys() #dct_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n",
    "    plt.plot(hist.epoch,hist.history.get('loss'),'r',label='loss')\n",
    "    plt.plot(hist.epoch,hist.history.get('val_loss'),'b',label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7df0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
